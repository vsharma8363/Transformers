After the encoder stack, we have an embedded representation of the tokens, their position, and their attention scores (how they relate to one another in a sequence)

